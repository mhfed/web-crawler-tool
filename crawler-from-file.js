import axios from "axios";
import * as cheerio from "cheerio";
import fs from "fs";
import path from "path";
import { crawlerConfig } from "./config.js";
import { generateHtmlReport, saveDataInMultipleFormats, readUrlsFromFile } from "./utils.js";

// Import hÃ m crawlPage tá»« crawler.js (copy láº¡i Ä‘á»ƒ Ä‘á»™c láº­p)
async function crawlPage(url) {
  try {
    console.log(`Äang crawl: ${url}`);
    
    const { data } = await axios.get(url, {
      timeout: crawlerConfig.settings.requestTimeout,
      headers: {
        'User-Agent': crawlerConfig.settings.userAgent
      }
    });
    
    const $ = cheerio.load(data);
    
    // Láº¥y thÃ´ng tin cÆ¡ báº£n
    const title = $("title").text().trim();
    const description = $('meta[name="description"]').attr('content') || '';
    const keywords = $('meta[name="keywords"]').attr('content') || '';
    
    // Láº¥y ná»™i dung text tá»« body, loáº¡i bá» script vÃ  style
    $('script, style, nav, footer, header').remove();
    const text = $("body").text().replace(/\s+/g, " ").trim();
    
    // Láº¥y táº¥t cáº£ links
    const links = [];
    $('a[href]').each((i, el) => {
      const href = $(el).attr('href');
      const linkText = $(el).text().trim();
      if (href && linkText) {
        links.push({ href, text: linkText });
      }
    });
    
    // Láº¥y images
    const images = [];
    $('img[src]').each((i, el) => {
      const src = $(el).attr('src');
      const alt = $(el).attr('alt') || '';
      if (src) {
        images.push({ src, alt });
      }
    });
    
    return {
      url,
      title,
      description,
      keywords,
      text: text.substring(0, crawlerConfig.settings.maxTextLength),
      links: links.slice(0, crawlerConfig.settings.maxLinks),
      images: images.slice(0, crawlerConfig.settings.maxImages),
      crawledAt: new Date().toISOString()
    };
    
  } catch (error) {
    console.error(`Lá»—i khi crawl ${url}:`, error.message);
    return {
      url,
      error: error.message,
      crawledAt: new Date().toISOString()
    };
  }
}

// HÃ m chá» (delay) giá»¯a cÃ¡c request
function delay(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

// HÃ m chÃ­nh Ä‘á»ƒ crawl tá»« file URLs
async function crawlFromFile(urlsFile = 'urls.txt') {
  console.log(`ğŸ“‚ Äá»c URLs tá»« file: ${urlsFile}`);
  
  const urls = readUrlsFromFile(urlsFile);
  
  if (urls.length === 0) {
    console.log('âŒ KhÃ´ng tÃ¬m tháº¥y URLs há»£p lá»‡ trong file!');
    console.log('Vui lÃ²ng kiá»ƒm tra file urls.txt vÃ  thÃªm URLs.');
    return;
  }
  
  const pages = [];
  const delayTime = crawlerConfig.settings.delayBetweenRequests;
  
  console.log(`ğŸš€ Báº¯t Ä‘áº§u crawl ${urls.length} trang tá»« file...`);
  
  for (let i = 0; i < urls.length; i++) {
    const url = urls[i];
    const page = await crawlPage(url);
    pages.push(page);
    
    // Hiá»ƒn thá»‹ tiáº¿n Ä‘á»™
    const progress = ((i + 1) / urls.length * 100).toFixed(1);
    console.log(`â³ Tiáº¿n Ä‘á»™: ${i + 1}/${urls.length} (${progress}%)`);
    
    // Chá» giá»¯a cÃ¡c request Ä‘á»ƒ trÃ¡nh spam
    if (i < urls.length - 1) {
      await delay(delayTime);
    }
  }
  
  // Táº¡o thÆ° má»¥c output náº¿u chÆ°a cÃ³
  const outputDir = crawlerConfig.output.directory;
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir);
  }
  
  // LÆ°u káº¿t quáº£ dÆ°á»›i nhiá»u Ä‘á»‹nh dáº¡ng
  saveDataInMultipleFormats(pages, outputDir, "crawl_from_file");
  
  console.log(`âœ… HoÃ n thÃ nh! ÄÃ£ crawl ${pages.length} trang tá»« file.`);
  
  // Táº¡o bÃ¡o cÃ¡o tÃ³m táº¯t
  const summary = {
    totalPages: pages.length,
    successfulPages: pages.filter(p => !p.error).length,
    failedPages: pages.filter(p => p.error).length,
    sourceFile: urlsFile,
    crawledAt: new Date().toISOString()
  };
  
  const summaryFile = path.join(outputDir, "crawl_from_file_summary.json");
  fs.writeFileSync(summaryFile, JSON.stringify(summary, null, 2), 'utf8');
  
  // Táº¡o bÃ¡o cÃ¡o HTML
  generateHtmlReport(pages, outputDir);
  
  console.log(`ğŸ“Š BÃ¡o cÃ¡o tÃ³m táº¯t: ${summaryFile}`);
  console.log(`   - ThÃ nh cÃ´ng: ${summary.successfulPages} trang`);
  console.log(`   - Tháº¥t báº¡i: ${summary.failedPages} trang`);
  console.log(`   - File nguá»“n: ${summary.sourceFile}`);
}

// Cháº¡y crawler tá»« file
(async () => {
  try {
    const urlsFile = process.argv[2] || 'urls.txt';
    await crawlFromFile(urlsFile);
  } catch (error) {
    console.error("Lá»—i trong quÃ¡ trÃ¬nh crawl tá»« file:", error);
  }
})(); 